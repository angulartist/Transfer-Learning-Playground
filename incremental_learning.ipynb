{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "import h5py as h5\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Creme-ML\n",
    "from creme import optim\n",
    "from creme.linear_model import LogisticRegression\n",
    "from creme.multiclass import OneVsRestClassifier\n",
    "from creme.preprocessing import StandardScaler\n",
    "from creme.compose import Pipeline\n",
    "from creme import metrics\n",
    "from creme import stream\n",
    "from creme import compat\n",
    "from creme import model_selection\n",
    "from creme import ensemble\n",
    "\n",
    "from h5imagegenerator import HDF5ImageGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_h5_stream(src, *, X_key, y_key):\n",
    "    \"\"\"HDF Generator Factory\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    src : str\n",
    "        HDF source file path\n",
    "    X_key : str\n",
    "        HDF features dataset key\n",
    "    y_key : str\n",
    "        HDF labels dataset key\n",
    "        \n",
    "    Notes\n",
    "    -----\n",
    "    X_key and y_key must be passed as\n",
    "    keyword args only.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    generator\n",
    "        A generator that yields one\n",
    "        observation at a time.\n",
    "    \"\"\"\n",
    "    # Creme-ml works with dict instead of ndarrays\n",
    "    # Each feature has a column name\n",
    "    with h5.File(src, 'r') as source:\n",
    "        columns = [f'feat_{feature_idx}'\n",
    "                   for feature_idx\n",
    "                   in range(source[X_key].shape[1])]\n",
    "\n",
    "    def streamer():\n",
    "        \"\"\"HDF Generator\"\"\"\n",
    "        cursor = 0\n",
    "\n",
    "        while True:\n",
    "            with h5.File(src, 'r') as source:                     \n",
    "                try:\n",
    "                    X_train = source[X_key][cursor]\n",
    "                    y_train = source[y_key][cursor]\n",
    "                except (ValueError, IndexError):\n",
    "                    raise StopIteration('No more observations.')\n",
    "\n",
    "            cursor += 1\n",
    "\n",
    "            yield dict(zip(columns, X_train)), y_train\n",
    "            \n",
    "    return streamer()\n",
    "\n",
    "\n",
    "stream = build_h5_stream(\n",
    "    'features_train.h5',\n",
    "    X_key='images',\n",
    "    y_key='labels',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier (\n",
       "  model=LogisticRegression (\n",
       "    optimizer=SGD (\n",
       "      lr=Constant (\n",
       "        learning_rate=0.01\n",
       "      )\n",
       "    )\n",
       "    loss=Log ()\n",
       "    l2=0.\n",
       "    intercept=0.\n",
       "    intercept_lr=Constant (\n",
       "      learning_rate=0.01\n",
       "    )\n",
       "    clip_gradient=1e+12\n",
       "    initializer=Zeros ()\n",
       "  )\n",
       "  n_models=3\n",
       "  seed=None\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optim = optim.SGD(lr=0.01)\n",
    "\n",
    "model = ensemble.AdaBoostClassifier(\n",
    "    model=(\n",
    "        LogisticRegression(optimizer=optim)\n",
    "    ),\n",
    "    n_models=3,\n",
    ")\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = metrics.Accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = metrics.ConfusionMatrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10] Accuracy: 30.00%\n",
      "[20] Accuracy: 50.00%\n",
      "[30] Accuracy: 63.33%\n",
      "[40] Accuracy: 72.50%\n",
      "[50] Accuracy: 74.00%\n",
      "[60] Accuracy: 76.67%\n",
      "[70] Accuracy: 78.57%\n",
      "[80] Accuracy: 81.25%\n",
      "[90] Accuracy: 81.11%\n",
      "[100] Accuracy: 82.00%\n",
      "[110] Accuracy: 81.82%\n",
      "[120] Accuracy: 83.33%\n",
      "[130] Accuracy: 83.08%\n",
      "[140] Accuracy: 82.14%\n",
      "[150] Accuracy: 81.33%\n",
      "[160] Accuracy: 82.50%\n",
      "[170] Accuracy: 83.53%\n",
      "[180] Accuracy: 82.78%\n",
      "[190] Accuracy: 83.16%\n",
      "[200] Accuracy: 83.50%\n",
      "[210] Accuracy: 83.81%\n",
      "[220] Accuracy: 84.55%\n",
      "[230] Accuracy: 85.22%\n",
      "[240] Accuracy: 85.42%\n",
      "[250] Accuracy: 85.20%\n",
      "[260] Accuracy: 85.00%\n",
      "[270] Accuracy: 85.19%\n",
      "[280] Accuracy: 85.00%\n",
      "[290] Accuracy: 84.48%\n",
      "[300] Accuracy: 85.00%\n",
      "[310] Accuracy: 84.52%\n",
      "[320] Accuracy: 84.37%\n",
      "[330] Accuracy: 84.55%\n",
      "[340] Accuracy: 85.00%\n",
      "[350] Accuracy: 85.14%\n",
      "[360] Accuracy: 85.00%\n",
      "[370] Accuracy: 84.86%\n",
      "[380] Accuracy: 84.74%\n",
      "[390] Accuracy: 84.87%\n",
      "[400] Accuracy: 84.25%\n",
      "[410] Accuracy: 84.15%\n",
      "[420] Accuracy: 84.29%\n",
      "[430] Accuracy: 84.42%\n",
      "[440] Accuracy: 84.32%\n",
      "[450] Accuracy: 84.00%\n",
      "[460] Accuracy: 84.13%\n",
      "[470] Accuracy: 84.47%\n",
      "[480] Accuracy: 84.79%\n",
      "[490] Accuracy: 84.90%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Accuracy: 84.74%"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_selection.progressive_val_score(stream, model, metric, print_every=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"for X, y in stream:\n",
    "    y_hat = model.predict_one(X)\n",
    "    model = model.fit_one(X, y)\n",
    "\n",
    "    # Update the metrics\n",
    "    metric = metric.update(y_true=y, y_pred=y_hat)\n",
    "    cm = cm.update(y_true=y, y_pred=y_hat)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         False      1\n",
       "      0    219     30\n",
       "      1     32    217"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
